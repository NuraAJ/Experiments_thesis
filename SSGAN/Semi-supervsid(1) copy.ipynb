{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import sys; print(sys.path);\n",
    "#!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pickle as pkl\n",
    "import time\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import tensorflow as tf\n",
    "\n",
    "# There are two ways of solving this problem.\n",
    "# One is to have the matmul at the last layer output all 11 classes.\n",
    "# The other is to output just 10 classes, and use a constant value of 0 for\n",
    "# the logit for the last class. This still works because the softmax only needs\n",
    "# n independent logits to specify a probability distribution over n + 1 categories.\n",
    "# We implemented both solutions here.\n",
    "extra_class = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/nouraahmed/Desktop/Top_10_no_aug'\n",
    "\n",
    "classes = os.listdir(DATA_DIR)\n",
    "\n",
    "all_data = []\n",
    "y_data = []\n",
    "\n",
    "for id_class in range(len(classes)):\n",
    "    each_class = classes[id_class]\n",
    "    print (each_class)\n",
    "    if each_class == '.DS_Store':\n",
    "        continue\n",
    "    files = os.listdir(DATA_DIR +'/' + each_class)\n",
    "    \n",
    "    for im_path in files:\n",
    "        full_path = DATA_DIR + '/' + each_class + '/' + im_path\n",
    "        if im_path == '.DS_Store':\n",
    "            continue\n",
    "        im = scipy.misc.imread(full_path)\n",
    "        im = scipy.misc.imresize(im, (32, 32))\n",
    "        all_data.append(im)\n",
    "        y_data.append(id_class)\n",
    "        if not im.shape == (32, 32, 3):\n",
    "            print (each_class + '/' + im_path)\n",
    "\n",
    "X_data = np.zeros((32, 32, 3, len(y_data)), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ix in range(len(y_data)):\n",
    "    X_data[:, :, :, ix] = all_data[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_data = np.asarray(y_data)\n",
    "# print (X_data.shape)\n",
    "# print (y_data, len(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.imshow(X_data[:, :, :, 7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = {'X': None, 'y': None}\n",
    "testset = {'X': None, 'y': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decide what % of the data goes into training\n",
    "split = int(0.90 * len(y_data))\n",
    "# print(split)\n",
    "idx = range(len(y_data))\n",
    "idx = list(idx)\n",
    "#idx = np.random.shuffle(list(idx))\n",
    "#print(idx)\n",
    "np.random.shuffle(idx)\n",
    "print(idx)\n",
    "trainset['X'] = X_data[:, :, :, idx[:split]]\n",
    "testset['X'] = X_data[:, :, :, idx[split:]]\n",
    "\n",
    "trainset['y'] = y_data[idx[:split]]\n",
    "testset['y'] = y_data[idx[split:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print (trainset['X'].shape, testset['X'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, trainset['X'].shape[3], size=25)\n",
    "fig, axes = plt.subplots(5, 5, sharex=True, sharey=True, figsize=(5,5),)\n",
    "for ii, ax in zip(idx, axes.flatten()):\n",
    "    ax.imshow(trainset['X'][:,:,:,ii], aspect='equal')\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale(x, feature_range=(-1, 1)):\n",
    "    # scale to (0, 1)\n",
    "    x = ((x - x.min())/(255 - x.min()))\n",
    "    \n",
    "    # scale to feature_range\n",
    "    min, max = feature_range\n",
    "    x = x * (max - min) + min\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu(x, alpha=0.2, name=None):\n",
    "    return tf.maximum(alpha * x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, train, test, val_frac=0.5, shuffle=True, scale_func=None):\n",
    "        split_idx = int(len(test['y'])*(1 - val_frac))\n",
    "        self.test_x, self.valid_x = test['X'][:,:,:,:split_idx], test['X'][:,:,:,split_idx:]\n",
    "        self.test_y, self.valid_y = test['y'][:split_idx], test['y'][split_idx:]\n",
    "        self.train_x, self.train_y = train['X'], train['y']\n",
    "        # The SVHN dataset comes with lots of labels, but for the purpose of this exercise,\n",
    "        # we will pretend that there are only 1000.\n",
    "        # We use this mask to say which labels we will allow ourselves to use.\n",
    "        self.label_mask = np.zeros_like(self.train_y)\n",
    "        self.label_mask[0:len(self.train_y)] = 1\n",
    "        \n",
    "        self.train_x = np.rollaxis(self.train_x, 3)\n",
    "        self.valid_x = np.rollaxis(self.valid_x, 3)\n",
    "        self.test_x = np.rollaxis(self.test_x, 3)\n",
    "        \n",
    "        if scale_func is None:\n",
    "            self.scaler = scale\n",
    "        else:\n",
    "            self.scaler = scale_func\n",
    "        self.train_x = self.scaler(self.train_x)\n",
    "        self.valid_x = self.scaler(self.valid_x)\n",
    "        self.test_x = self.scaler(self.test_x)\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "    def batches(self, batch_size, which_set=\"train\"):\n",
    "        x_name = which_set + \"_x\"\n",
    "        y_name = which_set + \"_y\"\n",
    "        \n",
    "        num_examples = len(getattr(dataset, y_name))\n",
    "        if self.shuffle:\n",
    "            idx = np.arange(num_examples)\n",
    "            np.random.shuffle(idx)\n",
    "            setattr(dataset, x_name, getattr(dataset, x_name)[idx])\n",
    "            setattr(dataset, y_name, getattr(dataset, y_name)[idx])\n",
    "            if which_set == \"train\":\n",
    "                dataset.label_mask = dataset.label_mask[idx]\n",
    "        \n",
    "        dataset_x = getattr(dataset, x_name)\n",
    "        dataset_y = getattr(dataset, y_name)\n",
    "        for ii in range(0, num_examples, batch_size):\n",
    "            x = dataset_x[ii:ii+batch_size]\n",
    "            y = dataset_y[ii:ii+batch_size]\n",
    "            \n",
    "            if which_set == \"train\":\n",
    "                # When we use the data for training, we need to include\n",
    "                # the label mask, so we can pretend we don't have access\n",
    "                # to some of the labels, as an exercise of our semi-supervised\n",
    "                # learning ability\n",
    "                yield x, y, self.label_mask[ii:ii+batch_size]\n",
    "            else:\n",
    "                yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_inputs(real_dim, z_dim):\n",
    "    inputs_real = tf.placeholder(tf.float32, (None, *real_dim), name='input_real')\n",
    "    inputs_z = tf.placeholder(tf.float32, (None, z_dim), name='input_z')\n",
    "    y = tf.placeholder(tf.int32, (None), name='y')\n",
    "    label_mask = tf.placeholder(tf.int32, (None), name='label_mask')\n",
    "    \n",
    "    return inputs_real, inputs_z, y, label_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def discriminator(x, reuse=False, alpha=0.2, drop_rate=0., num_classes=10, size_mult=64):\n",
    "#     with tf.variable_scope('discriminator', reuse=reuse):\n",
    "#         x = tf.layers.dropout(x, rate=drop_rate/2.5)\n",
    "#         #d1 \n",
    "#         x_1 = tf.layers.conv2d(x, size_mult, 3, strides=2, padding='same')\n",
    "#         lrelu_1 = leaky_relu(x_1, alpha) \n",
    "#         bn_1 = tf.layers.batch_normalization(lrelu_1, training=True)\n",
    "#         drop_1 = tf.layers.dropout(bn_1, rate=drop_rate)\n",
    "        \n",
    "#         #d2 \n",
    "#         x_2 = tf.layers.conv2d(drop_1, size_mult, 3, strides=2, padding='same')\n",
    "#         lrelu_2 = leaky_relu(x_2, alpha)\n",
    "#         bn_2 = tf.layers.batch_normalization(lrelu_2, training=True)\n",
    "#         drop_2 = tf.layers.dropout(bn_2, rate=drop_rate)\n",
    "        \n",
    "#         #d3 \n",
    "#         x_3 = tf.layers.conv2d(drop_2, size_mult, 3, strides=2, padding='same')\n",
    "#         lrelu_3 = leaky_relu(x_3, alpha)\n",
    "#         bn_3 = tf.layers.batch_normalization(lrelu_3, training=True)\n",
    "#         drop_3 = tf.layers.dropout(bn_3, rate=drop_rate)\n",
    "        \n",
    "#         #d4 \n",
    "#         x_4 = tf.layers.conv2d(drop_3, 2 * size_mult, 3, strides=1, padding='same')\n",
    "#         lrelu_4 = leaky_relu(x_4, alpha)\n",
    "#         bn_4 = tf.layers.batch_normalization(lrelu_4, training=True)\n",
    "#         drop_4 = tf.layers.dropout(bn_4, rate=drop_rate)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         x_5 = tf.layers.conv2d(drop_4, 2 * size_mult, 3, strides=1, padding='valid')\n",
    "#         relu5 = leaky_relu(x_5, alpha)\n",
    "        \n",
    "#         features = tf.reduce_mean(relu5, (1, 2))\n",
    "        \n",
    "#         class_logits = tf.layers.dense(features, num_classes + extra_class)\n",
    "        \n",
    "#         if extra_class:\n",
    "#             real_class_logits, fake_class_logits = tf.split(class_logits, [num_classes, 1], 1)\n",
    "#             assert fake_class_logits.get_shape()[1] == 1, fake_class_logits.get_shape()\n",
    "#             fake_class_logits = tf.squeeze(fake_class_logits)\n",
    "#         else:\n",
    "#             real_class_logits = class_logits\n",
    "#             fake_class_logits = 0.\n",
    "        \n",
    "#         mx = tf.reduce_max(real_class_logits, 1, keep_dims=True)\n",
    "#         stable_real_class_logits = real_class_logits - mx\n",
    "\n",
    "#         gan_logits = tf.log(tf.reduce_sum(tf.exp(stable_real_class_logits), 1)) + tf.squeeze(mx) - fake_class_logits\n",
    "        \n",
    "#         out = tf.nn.softmax(class_logits)\n",
    "        \n",
    "#         return out, class_logits, gan_logits, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def generator(z, output_dim, reuse=False, alpha=0.2, training=True, size_mult=128):\n",
    "#     with tf.variable_scope('generator', reuse=reuse):\n",
    "#         x1 = tf.layers.dense(z, 4 * 4 * size_mult * 4)\n",
    "#         x1 = tf.reshape(x1, (-1, 4, 4, size_mult * 4))\n",
    "#         x1 = leaky_relu(x1, alpha)\n",
    "#         x1 = tf.layers.batch_normalization(x1, training=training)\n",
    "#         #x1 = tf.maximum(alpha * x1, x1)\n",
    "        \n",
    "#         x2 = tf.layers.conv2d_transpose(x1, size_mult * 2, 5, strides=2, padding='same')\n",
    "#         x2 = leaky_relu(x2, alpha)\n",
    "#         x2 = tf.layers.batch_normalization(x2, training=training)\n",
    "#         #x2 = tf.maximum(alpha * x2, x2)\n",
    "        \n",
    "#         x3 = tf.layers.conv2d_transpose(x2, size_mult, 5, strides=2, padding='same')\n",
    "#         x3 = leaky_relu(x3, alpha)\n",
    "#         x3 = tf.layers.batch_normalization(x3, training=training)\n",
    "#         #x3 = tf.maximum(alpha * x3, x3)\n",
    "        \n",
    "#         # Output layer\n",
    "#         logits = tf.layers.conv2d_transpose(x3, output_dim, 5, strides=2, padding='same')\n",
    "        \n",
    "#         out = tf.tanh(logits)\n",
    "        \n",
    "#         return out\n",
    "def generator(z, output_dim, reuse=False, alpha=0.2, training=True, size_mult=128):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        x1 = tf.layers.dense(z, 4 * 4 * size_mult * 4)\n",
    "        # Reshape it to start the convolutional stack\n",
    "        x1 = tf.reshape(x1, (-1, 4, 4, size_mult * 4))\n",
    "        x1 = tf.layers.batch_normalization(x1, training=training)\n",
    "        x1 = tf.maximum(alpha * x1, x1)\n",
    "        \n",
    "        x2 = tf.layers.conv2d_transpose(x1, size_mult * 2, 5, strides=2, padding='same')\n",
    "        x2 = tf.layers.batch_normalization(x2, training=training)\n",
    "        x2 = tf.maximum(alpha * x2, x2)\n",
    "        \n",
    "        x3 = tf.layers.conv2d_transpose(x2, size_mult, 5, strides=2, padding='same')\n",
    "        x3 = tf.layers.batch_normalization(x3, training=training)\n",
    "        x3 = tf.maximum(alpha * x3, x3)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.conv2d_transpose(x3, output_dim, 5, strides=2, padding='same')\n",
    "        \n",
    "        out = tf.tanh(logits)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def discriminator(x, reuse=False, alpha=0.2, drop_rate=0., num_classes=10, size_mult=64):\n",
    "#     with tf.variable_scope('discriminator', reuse=reuse):\n",
    "#         x = tf.layers.dropout(x, rate=drop_rate/2.5)\n",
    "        \n",
    "#         # Input layer is 32x32x3\n",
    "#         x1 = tf.layers.conv2d(x, size_mult, 3, strides=2, padding='same')\n",
    "#         relu1 = tf.maximum(alpha * x1, x1)\n",
    "#         relu1 = tf.layers.dropout(relu1, rate=drop_rate)\n",
    "        \n",
    "#         x2 = tf.layers.conv2d(relu1, size_mult, 3, strides=2, padding='same')\n",
    "#         bn2 = tf.layers.batch_normalization(x2, training=True)\n",
    "#         relu2 = tf.maximum(alpha * x2, x2)\n",
    "        \n",
    "        \n",
    "#         x3 = tf.layers.conv2d(relu2, size_mult, 3, strides=2, padding='same')\n",
    "#         bn3 = tf.layers.batch_normalization(x3, training=True)\n",
    "#         relu3 = tf.maximum(alpha * bn3, bn3)\n",
    "#         relu3 = tf.layers.dropout(relu3, rate=drop_rate)\n",
    "        \n",
    "#         x4 = tf.layers.conv2d(relu3, 2 * size_mult, 3, strides=1, padding='same')\n",
    "#         bn4 = tf.layers.batch_normalization(x4, training=True)\n",
    "#         relu4 = tf.maximum(alpha * bn4, bn4)\n",
    "        \n",
    "#         x5 = tf.layers.conv2d(relu4, 2 * size_mult, 3, strides=1, padding='same')\n",
    "#         bn5 = tf.layers.batch_normalization(x5, training=True)\n",
    "#         relu5 = tf.maximum(alpha * bn5, bn5)\n",
    "        \n",
    "#         x6 = tf.layers.conv2d(relu5, 2 * size_mult, 3, strides=2, padding='same')\n",
    "#         bn6 = tf.layers.batch_normalization(x6, training=True)\n",
    "#         relu6 = tf.maximum(alpha * bn6, bn6)\n",
    "#         relu6 = tf.layers.dropout(relu6, rate=drop_rate)\n",
    "        \n",
    "#         x7 = tf.layers.conv2d(relu5, 2 * size_mult, 3, strides=1, padding='valid')\n",
    "\n",
    "#         relu7 = tf.maximum(alpha * x7, x7)\n",
    "        \n",
    "#         features = tf.reduce_mean(relu7, (1, 2))\n",
    "        \n",
    "#         class_logits = tf.layers.dense(features, num_classes + extra_class)\n",
    "        \n",
    "#         if extra_class:\n",
    "#             real_class_logits, fake_class_logits = tf.split(class_logits, [num_classes, 1], 1)\n",
    "#             assert fake_class_logits.get_shape()[1] == 1, fake_class_logits.get_shape()\n",
    "#             fake_class_logits = tf.squeeze(fake_class_logits)\n",
    "#         else:\n",
    "#             real_class_logits = class_logits\n",
    "#             fake_class_logits = 0.\n",
    "        \n",
    "#         mx = tf.reduce_max(real_class_logits, 1, keep_dims=True)\n",
    "#         stable_real_class_logits = real_class_logits - mx\n",
    "\n",
    "#         gan_logits = tf.log(tf.reduce_sum(tf.exp(stable_real_class_logits), 1)) + tf.squeeze(mx) - fake_class_logits\n",
    "        \n",
    "#         out = tf.nn.softmax(class_logits)\n",
    "        \n",
    "#         return out, class_logits, gan_logits, features\n",
    "def discriminator(x, reuse=False, alpha=0.2, drop_rate=0., num_classes=10, size_mult=64):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        x = tf.layers.dropout(x, rate=drop_rate/2.5)\n",
    "        \n",
    "        # Input layer is 32x32x3\n",
    "        x1 = tf.layers.conv2d(x, size_mult, 3, strides=2, padding='same')\n",
    "        relu1 = tf.maximum(alpha * x1, x1)\n",
    "        relu1 = tf.layers.dropout(relu1, rate=drop_rate)\n",
    "        \n",
    "        x2 = tf.layers.conv2d(relu1, size_mult, 3, strides=2, padding='same')\n",
    "        bn2 = tf.layers.batch_normalization(x2, training=True)\n",
    "        relu2 = tf.maximum(alpha * x2, x2)\n",
    "        \n",
    "        \n",
    "        x3 = tf.layers.conv2d(relu2, size_mult, 3, strides=2, padding='same')\n",
    "        bn3 = tf.layers.batch_normalization(x3, training=True)\n",
    "        relu3 = tf.maximum(alpha * bn3, bn3)\n",
    "        relu3 = tf.layers.dropout(relu3, rate=drop_rate)\n",
    "        \n",
    "        x4 = tf.layers.conv2d(relu3, 2 * size_mult, 3, strides=1, padding='same')\n",
    "        bn4 = tf.layers.batch_normalization(x4, training=True)\n",
    "        relu4 = tf.maximum(alpha * bn4, bn4)\n",
    "        \n",
    "        x5 = tf.layers.conv2d(relu4, 2 * size_mult, 3, strides=1, padding='same')\n",
    "        bn5 = tf.layers.batch_normalization(x5, training=True)\n",
    "        relu5 = tf.maximum(alpha * bn5, bn5)\n",
    "        \n",
    "        x6 = tf.layers.conv2d(relu5, 2 * size_mult, 3, strides=2, padding='same')\n",
    "        bn6 = tf.layers.batch_normalization(x6, training=True)\n",
    "        relu6 = tf.maximum(alpha * bn6, bn6)\n",
    "        relu6 = tf.layers.dropout(relu6, rate=drop_rate)\n",
    "        \n",
    "        x7 = tf.layers.conv2d(relu5, 2 * size_mult, 3, strides=1, padding='valid')\n",
    "        # Don't use bn on this layer, because bn would set the mean of each feature\n",
    "        # to the bn mu parameter.\n",
    "        # This layer is used for the feature matching loss, which only works if\n",
    "        # the means can be different when the discriminator is run on the data than\n",
    "        # when the discriminator is run on the generator samples.\n",
    "        relu7 = tf.maximum(alpha * x7, x7)\n",
    "        \n",
    "        # Flatten it by global average pooling\n",
    "        features = tf.reduce_mean(relu7, (1, 2))\n",
    "        \n",
    "        # Set class_logits to be the inputs to a softmax distribution over the different classes\n",
    "        class_logits = tf.layers.dense(features, num_classes + extra_class)\n",
    "        \n",
    "        \n",
    "        # Set gan_logits such that P(input is real | input) = sigmoid(gan_logits).\n",
    "        # Keep in mind that class_logits gives you the probability distribution over all the real\n",
    "        # classes and the fake class. You need to work out how to transform this multiclass softmax\n",
    "        # distribution into a binary real-vs-fake decision that can be described with a sigmoid.\n",
    "        # Numerical stability is very important.\n",
    "        # You'll probably need to use this numerical stability trick:\n",
    "        # log sum_i exp a_i = m + log sum_i exp(a_i - m).\n",
    "        # This is numerically stable when m = max_i a_i.\n",
    "        # (It helps to think about what goes wrong when...\n",
    "        #   1. One value of a_i is very large\n",
    "        #   2. All the values of a_i are very negative\n",
    "        # This trick and this value of m fix both those cases, but the naive implementation and\n",
    "        # other values of m encounter various problems)\n",
    "        \n",
    "        if extra_class:\n",
    "            real_class_logits, fake_class_logits = tf.split(class_logits, [num_classes, 1], 1)\n",
    "            assert fake_class_logits.get_shape()[1] == 1, fake_class_logits.get_shape()\n",
    "            fake_class_logits = tf.squeeze(fake_class_logits)\n",
    "        else:\n",
    "            real_class_logits = class_logits\n",
    "            fake_class_logits = 0.\n",
    "        \n",
    "        mx = tf.reduce_max(real_class_logits, 1, keep_dims=True)\n",
    "        stable_real_class_logits = real_class_logits - mx\n",
    "\n",
    "        gan_logits = tf.log(tf.reduce_sum(tf.exp(stable_real_class_logits), 1)) + tf.squeeze(mx) - fake_class_logits\n",
    "        \n",
    "        out = tf.nn.softmax(class_logits)\n",
    "        \n",
    "        return out, class_logits, gan_logits, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_loss(input_real, input_z, output_dim, y, num_classes, label_mask, alpha=0.2, drop_rate=0.):\n",
    "    \"\"\"\n",
    "    Get the loss for the discriminator and generator\n",
    "    :param input_real: Images from the real dataset\n",
    "    :param input_z: Z input\n",
    "    :param output_dim: The number of channels in the output image\n",
    "    :param y: Integer class labels\n",
    "    :param num_classes: The number of classes\n",
    "    :param alpha: The slope of the left half of leaky ReLU activation\n",
    "    :param drop_rate: The probability of dropping a hidden unit\n",
    "    :return: A tuple of (discriminator loss, generator loss)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # These numbers multiply the size of each layer of the generator and the discriminator,\n",
    "    # respectively. You can reduce them to run your code faster for debugging purposes.\n",
    "    g_size_mult = 32\n",
    "    d_size_mult = 64\n",
    "    \n",
    "    # Here we run the generator and the discriminator\n",
    "    g_model = generator(input_z, output_dim, alpha=alpha, size_mult=g_size_mult)\n",
    "    d_on_data = discriminator(input_real, alpha=alpha, drop_rate=drop_rate, size_mult=d_size_mult)\n",
    "    d_model_real, class_logits_on_data, gan_logits_on_data, data_features = d_on_data\n",
    "    d_on_samples = discriminator(g_model, reuse=True, alpha=alpha, drop_rate=drop_rate, size_mult=d_size_mult)\n",
    "    d_model_fake, class_logits_on_samples, gan_logits_on_samples, sample_features = d_on_samples\n",
    "    \n",
    "    \n",
    "    # Here we compute `d_loss`, the loss for the discriminator.\n",
    "    # This should combine two different losses:\n",
    "    #  1. The loss for the GAN problem, where we minimize the cross-entropy for the binary\n",
    "    #     real-vs-fake classification problem.\n",
    "    #  2. The loss for the SVHN digit classification problem, where we minimize the cross-entropy\n",
    "    #     for the multi-class softmax. For this one we use the labels. Don't forget to ignore\n",
    "    #     use `label_mask` to ignore the examples that we are pretending are unlabeled for the\n",
    "    #     semi-supervised learning problem.\n",
    "    d_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=gan_logits_on_data,\n",
    "                                                labels=tf.ones_like(gan_logits_on_data)))\n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=gan_logits_on_samples,\n",
    "                                                labels=tf.zeros_like(gan_logits_on_samples)))\n",
    "    y = tf.squeeze(y)\n",
    "    class_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=class_logits_on_data,\n",
    "                                                                  labels=tf.one_hot(y, num_classes + extra_class,\n",
    "                                                                                    dtype=tf.float32))\n",
    "    class_cross_entropy = tf.squeeze(class_cross_entropy)\n",
    "    label_mask = tf.squeeze(tf.to_float(label_mask))\n",
    "    d_loss_class = tf.reduce_sum(label_mask * class_cross_entropy) / tf.maximum(1., tf.reduce_sum(label_mask))\n",
    "    d_loss = d_loss_class + d_loss_real + d_loss_fake\n",
    "    \n",
    "    # Here we set `g_loss` to the \"feature matching\" loss invented by Tim Salimans at OpenAI.\n",
    "    # This loss consists of minimizing the absolute difference between the expected features\n",
    "    # on the data and the expected features on the generated samples.\n",
    "    # This loss works better for semi-supervised learning than the tradition GAN losses.\n",
    "    data_moments = tf.reduce_mean(data_features, axis=0)\n",
    "    sample_moments = tf.reduce_mean(sample_features, axis=0)\n",
    "    g_loss = tf.reduce_mean(tf.abs(data_moments - sample_moments))\n",
    "\n",
    "    pred_class = tf.cast(tf.argmax(class_logits_on_data, 1), tf.int32)\n",
    "    eq = tf.equal(tf.squeeze(y), pred_class)\n",
    "    correct = tf.reduce_sum(tf.to_float(eq))\n",
    "    masked_correct = tf.reduce_sum(label_mask * tf.to_float(eq))\n",
    "    \n",
    "    return d_loss, g_loss, correct, masked_correct, g_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_opt(d_loss, g_loss, learning_rate, beta1):\n",
    "    \"\"\"\n",
    "    Get optimization operations\n",
    "    :param d_loss: Discriminator loss Tensor\n",
    "    :param g_loss: Generator loss Tensor\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :param beta1: The exponential decay rate for the 1st moment in the optimizer\n",
    "    :return: A tuple of (discriminator training operation, generator training operation)\n",
    "    \"\"\"\n",
    "    # Get weights and biases to update. Get them separately for the discriminator and the generator\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "    for t in t_vars:\n",
    "        assert t in d_vars or t in g_vars\n",
    "\n",
    "    # Minimize both players' costs simultaneously\n",
    "    d_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "    g_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "    shrink_lr = tf.assign(learning_rate, learning_rate * 0.9)\n",
    "    \n",
    "    return d_train_opt, g_train_opt, shrink_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    \"\"\"\n",
    "    A GAN model.\n",
    "    :param real_size: The shape of the real data.\n",
    "    :param z_size: The number of entries in the z code vector.\n",
    "    :param learnin_rate: The learning rate to use for Adam.\n",
    "    :param num_classes: The number of classes to recognize.\n",
    "    :param alpha: The slope of the left half of the leaky ReLU activation\n",
    "    :param beta1: The beta1 parameter for Adam.\n",
    "    \"\"\"\n",
    "    def __init__(self, real_size, z_size, learning_rate, num_classes=10, alpha=0.2, beta1=0.5):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.learning_rate = tf.Variable(learning_rate, trainable=False)\n",
    "        self.input_real, self.input_z, self.y, self.label_mask = model_inputs(real_size, z_size)\n",
    "        self.drop_rate = tf.placeholder_with_default(.5, (), \"drop_rate\")\n",
    "        \n",
    "        loss_results = model_loss(self.input_real, self.input_z,\n",
    "                                              real_size[2], self.y, num_classes, label_mask=self.label_mask,\n",
    "                                                                          alpha=0.2,\n",
    "                                                           drop_rate=self.drop_rate)\n",
    "        self.d_loss, self.g_loss, self.correct, self.masked_correct, self.samples = loss_results\n",
    "        \n",
    "        self.d_opt, self.g_opt, self.shrink_lr = model_opt(self.d_loss, self.g_loss, self.learning_rate, beta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_samples(epoch, samples, nrows, ncols, figsize=(5,5)):\n",
    "    fig, axes = plt.subplots(figsize=figsize, nrows=nrows, ncols=ncols, \n",
    "                             sharey=True, sharex=True)\n",
    "    for ax, img in zip(axes.flatten(), samples[epoch]):\n",
    "        ax.axis('off')\n",
    "        img = ((img - img.min())*255 / (img.max() - img.min())).astype(np.uint8)\n",
    "        ax.set_adjustable('box-forced')\n",
    "        im = ax.imshow(img)\n",
    "   \n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(net, dataset, epochs, batch_size, figsize=(5,5)):\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    sample_z = np.random.normal(0, 1, size=(50, z_size))\n",
    "\n",
    "    samples, train_accuracies, test_accuracies = [], [], []\n",
    "    steps = 0\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for e in range(epochs):\n",
    "            print(\"Epoch\",e)\n",
    "            \n",
    "            t1e = time.time()\n",
    "            num_examples = 0\n",
    "            num_correct = 0\n",
    "            for x, y, label_mask in dataset.batches(batch_size):\n",
    "                assert 'int' in str(y.dtype)\n",
    "                steps += 1\n",
    "                num_examples += label_mask.sum()\n",
    "\n",
    "                # Sample random noise for G\n",
    "                batch_z = np.random.normal(0, 1, size=(batch_size, z_size))\n",
    "\n",
    "                # Run optimizers\n",
    "                t1 = time.time()\n",
    "                _, _, correct = sess.run([net.d_opt, net.g_opt, net.masked_correct],\n",
    "                                         feed_dict={net.input_real: x, net.input_z: batch_z,\n",
    "                                                    net.y : y, net.label_mask : label_mask})\n",
    "                t2 = time.time()\n",
    "                num_correct += correct\n",
    "\n",
    "            sess.run([net.shrink_lr])\n",
    "            \n",
    "            \n",
    "            train_accuracy = num_correct / float(num_examples)\n",
    "            \n",
    "            print(\"\\t\\tClassifier train accuracy: \", train_accuracy)\n",
    "            \n",
    "            num_examples = 0\n",
    "            num_correct = 0\n",
    "            for x, y in dataset.batches(batch_size, which_set=\"test\"):\n",
    "                assert 'int' in str(y.dtype)\n",
    "                num_examples += x.shape[0]\n",
    "\n",
    "                correct, = sess.run([net.correct], feed_dict={net.input_real: x,\n",
    "                                                   net.y : y,\n",
    "                                                   net.drop_rate: 0.})\n",
    "                num_correct += correct\n",
    "            \n",
    "            test_accuracy = num_correct / float(num_examples)\n",
    "            print(\"\\t\\tClassifier test accuracy\", test_accuracy)\n",
    "            print(\"\\t\\tStep time: \", t2 - t1)\n",
    "            t2e = time.time()\n",
    "            print(\"\\t\\tEpoch time: \", t2e - t1e)\n",
    "            \n",
    "            \n",
    "            gen_samples = sess.run(\n",
    "                                   net.samples,\n",
    "                                   feed_dict={net.input_z: sample_z})\n",
    "            samples.append(gen_samples)\n",
    "            _ = view_samples(-1, samples, 5, 10, figsize=figsize)\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            # Save history of accuracies to view after training\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "            \n",
    "\n",
    "        saver.save(sess, './checkpoints/generator.ckpt')\n",
    "\n",
    "    with open('samples.pkl', 'wb') as f:\n",
    "        pkl.dump(samples, f)\n",
    "    \n",
    "    return train_accuracies, test_accuracies, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_size = (32,32,3)\n",
    "z_size = 100\n",
    "learning_rate = 0.0003\n",
    "\n",
    "net = GAN(real_size, z_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(trainset, testset)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 500\n",
    "train_accuracies, test_accuracies, samples = train(net, dataset, epochs, batch_size, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(train_accuracies, label='Train', alpha=0.5)\n",
    "plt.plot(test_accuracies, label='Test', alpha=0.5)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = view_samples(-1, samples, 5, 10, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = view_samples(-1, samples, 5, 10, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libs import vgg16, inception, i2v\n",
    "# SO: g = sess.run(feed_dict = {X : img, y = (Male or Female)})\n",
    "# out = sess.run(feed_dict={X: img, y : Male})\n",
    "\n",
    "# sess.close()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Stick w/ VGG for now, and then after you see how\n",
    "# the next few sections work w/ this network, come back\n",
    "# and explore the something else.\n",
    "\n",
    "net = vgg16.get_vgg_face_model()\n",
    "# Let's explicity use the CPU, since we don't gain anything using the GPU\n",
    "# when doing Deep Dream (it's only a single image, benefits come w/ many images).\n",
    "device = '/cpu:0'\n",
    "\n",
    "# We'll now explicitly create a graph\n",
    "g = tf.Graph()\n",
    "# And here is a context manager.  We use the python \"with\" notation to create a context\n",
    "# and create a session that only exists within this indent,  as soon as we leave it,\n",
    "# the session is automatically closed!  We also tel the session which graph to use.\n",
    "# We can pass a second context after the comma,\n",
    "# which we'll use to be explicit about using the CPU instead of a GPU.\n",
    "with tf.Session(graph=g) as sess, g.device(device):\n",
    "    \n",
    "    # Now load the graph_def, which defines operations and their values into `g`\n",
    "    tf.import_graph_def(net['graph_def'], name='net')\n",
    "    \n",
    "names = [op.name for op in g.get_operations()]\n",
    "def transferred_predictions(img):\n",
    "    # gets an image (`np.array`) as an input outputs net's final layer predictions \n",
    "    results = []\n",
    "    \n",
    "    # Grab the tensor defining the input to the network\n",
    "    x = g.get_tensor_by_name(names[0] + \":0\")\n",
    "\n",
    "    # And grab the tensor defining the softmax layer of the network\n",
    "    softmax = g.get_tensor_by_name(names[-2] + \":0\")\n",
    "    \n",
    "    with tf.Session(graph=g) as sess, g.device('/cpu:0'):\n",
    "        # Remember from the lecture that we have to set the dropout\n",
    "        # \"keep probability\" to 1.0.\n",
    "        res = softmax.eval(feed_dict={x: img } ) # , Not using droput here\n",
    "                    # 'net/dropout_1/random_uniform:0': [[1.0] * 4096],\n",
    "                    # 'net/dropout/random_uniform:0': [[1.0] * 4096]})\n",
    "        test_array = res.argsort()[-5:][::-1].flatten()\n",
    "        results = ([(res.flatten()[int(idx)], \n",
    "                net['labels'][int(idx)])\n",
    "               for idx in test_array ])\n",
    "\n",
    "        result = pd.DataFrame(results, columns=['score','label']) # .sort(columns='score')\n",
    "        \n",
    "        results.append(result.score)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def transferred_df(generated_data):\n",
    "    # does the preprocessing of the `list` of generated_data and outputs `list` of predictions\n",
    "    results = []\n",
    "    \n",
    "    for i in range(len(generated_data)):\n",
    "        img = imresize(generated_data[i], size=(224,224,3))\n",
    "        img = net['preprocess'](img)[np.newaxis]\n",
    "        result = transferred_predictions(img)\n",
    "        results.append(result)\n",
    "        \n",
    "        if i%1000==0:\n",
    "            print(\"Current image id {}\".format(i))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results = parallel_transfer_eval(generated_data[:20000])\n",
    "results = transferred_df(generated_data[:20000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
